init_checkpoint_path: weights/dit.safetensors
checkpoint_dir: finetunes/music_infuser
train_data_dir: videos_preprocessed_aist_73
train_data_dir_2: videos_preprocessed_aist_73 # Replace this to an in-the-wild dataset
train_data_dir_2_ratio: 0.0 # Indicates how much in-the-wild data will be used
attention_mode: sdpa
single_video_mode: false # Useful for debugging whether your model can learn a single video

seed: 42
audio_mode: cross_attn
basic_prompt_ratio: 0.2
beta_beta: 3
beta_half: 200

# You only need this if you're using wandb
wandb:
  project: mochi_1_music
  name: ${checkpoint_dir}
  group: null

optimizer:
  lr: 1e-4
  weight_decay: 0.0

model:
  type: lora+audio
  kwargs:
    # Apply LoRA to the QKV projection and the output projection of the attention block.
    qkv_proj_lora_rank: 64
    qkv_proj_lora_alpha: 64
    qkv_proj_lora_dropout: 0.
    out_proj_lora_rank: 64
    out_proj_lora_alpha: 64
    out_proj_lora_dropout: 0.

training:
  model_dtype: bf16
  warmup_steps: 200
  num_qkv_checkpoint: 48
  num_ff_checkpoint: 48
  num_post_attn_checkpoint: 48
  num_steps: 4000
  save_interval: 500
  caption_dropout: 0.1
  grad_clip: 0.0
  save_safetensors: true

# Used for generating samples during training to monitor progress ...
sample:
   interval: 999999999
   output_dir: ${checkpoint_dir}/samples
   decoder_path: weights/decoder.safetensors
   prompts:
   audios:
   seed: 42
   kwargs:
     height: 480
     width: 848
     num_frames: 73
     num_inference_steps: 64
     sigma_schedule_python_code: "linear_quadratic_schedule(64, 0.025)"
     cfg_schedule_python_code: "[6.0] * 64"